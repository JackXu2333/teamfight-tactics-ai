{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d97d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "import platform\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# Importing essential libraries for basic image manipulations.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tF\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38525ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Enable/Disable GPU \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59985ba2",
   "metadata": {},
   "source": [
    "### Create custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a12b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomVerticalFlip(p=0.5),\n",
    "     transforms.RandomHorizontalFlip(p=0.5)])\n",
    "\n",
    "trainset = CustomImageDataset(annotations_file = './data/af.csv', img_dir='./data', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea845c",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Champion_Net(nn.Module):\n",
    "    def __init__(self, num_classes, criterion):\n",
    "        super(MyNet, self).__init__()\n",
    "\n",
    "        # Implement me\n",
    "        model_ft = models.VGG16(pretrained=True)\n",
    "        model_ft.classifier[6] = nn.Linear(4096, num_classes)\n",
    "        \n",
    "        self.criterion = criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d41640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, num_epochs=25):\n",
    "    \n",
    "    since = time.time()\n",
    "    acc_list = []\n",
    "    model.train() # In training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Epoch information\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "        acc_list.append(epoch_acc)\n",
    "\n",
    "        print('Training Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ef055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloaders):\n",
    "    \n",
    "    since = time.time()\n",
    "    model.eval() # In training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    overall_loss = running_loss / len(dataloaders.dataset)\n",
    "    overall_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "\n",
    "    print('Evaluation Loss: {:.4f} Acc: {:.4f}'.format(overall_loss, overall_acc))\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return overall_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
