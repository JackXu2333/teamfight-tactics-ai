{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07829105",
   "metadata": {},
   "source": [
    "### Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "02c51363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "import platform\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# Importing essential libraries for basic image manipulations.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tF\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "c0dda42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Enable/Disable GPU \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5869f1",
   "metadata": {},
   "source": [
    "### Functions for transforming CNN annotation_file data to inputable data for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "f35ed853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_dnn(champion_label_df, champion_label_df_count):\n",
    "\n",
    "    s_list = []\n",
    "    o_list = []\n",
    "\n",
    "    for i in range(len(champion_label_df_count)):\n",
    "        youtuber = champion_label_df_count.iloc[i, :].youtuber\n",
    "        video_name = champion_label_df_count.iloc[i, :].video_name\n",
    "        frame_name = champion_label_df_count.iloc[i, :].frame_name\n",
    "\n",
    "        subdf = champion_label_df[(champion_label_df.youtuber == youtuber)&(champion_label_df.video_name == video_name)&(champion_label_df.frame_name == frame_name)]\n",
    "        subdf = subdf.loc[:, ['cropped_name', 'predicted']]\n",
    "\n",
    "\n",
    "        input_s = np.zeros(shape=(28,))\n",
    "        input_o = np.zeros(shape=(28,))\n",
    "\n",
    "        for j in range(len(subdf)):\n",
    "            cropped_name = subdf.iloc[j, :].cropped_name\n",
    "            predicted = subdf.iloc[j, :].predicted\n",
    "\n",
    "\n",
    "            # Find which player\n",
    "            player_type = re.search(r'S|O', cropped_name)\n",
    "            if player_type:\n",
    "                player_type = player_type[0]\n",
    "            else:\n",
    "                print('something wrong')\n",
    "            \n",
    "            champ_onehot = master_champ_list.index(predicted)\n",
    "\n",
    "\n",
    "            # Find which board index\n",
    "            board_index = re.search(r'\\d+', cropped_name)\n",
    "            if board_index:\n",
    "                board_index = int(board_index[0])\n",
    "            else:\n",
    "                print('something wrong')\n",
    "\n",
    "            if player_type == 'S':\n",
    "                input_s[board_index] = champ_onehot\n",
    "            elif player_type == 'O':\n",
    "                input_o[board_index] = champ_onehot\n",
    "\n",
    "        input_s = input_s.reshape((4, 7)).astype(int)\n",
    "        input_o = input_o.reshape((4, 7)).astype(int)\n",
    "        s_list.append(input_s)\n",
    "        o_list.append(input_o)\n",
    "\n",
    "    s, o = np.array(s_list), np.array(o_list)\n",
    "\n",
    "    return s, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "a47d8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_customimagedataset(s, o, y):\n",
    "    n = len(s)\n",
    "    # Proportion of test set size\n",
    "    test_size = 0.5\n",
    "    # Calculate where to split\n",
    "    test_start_idx = int(np.ceil(test_size * n))\n",
    "    # All indices of data\n",
    "    indices = np.arange(0, n)\n",
    "    # Shuffle indices array\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "    train_indices = indices[:test_start_idx]\n",
    "    test_indices = indices[test_start_idx:]\n",
    "\n",
    "    s_train = s[train_indices]\n",
    "    s_test = s[test_indices]\n",
    "    o_train = o[train_indices]\n",
    "    o_test = o[test_indices]\n",
    "\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return s_train, s_test, o_train, o_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "323a7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, s, o, y):\n",
    "        \n",
    "        self.s = s\n",
    "        self.o = o\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.s)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        board_s = self.s[idx]\n",
    "        board_o = self.o[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        return board_s, board_o, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "856a1e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9947, -0.4180,  0.0167],\n",
       "         [ 0.6942,  0.5163,  1.5398],\n",
       "         [-0.7825, -1.4319, -0.0774],\n",
       "         [-1.6815, -1.4351,  0.0784]],\n",
       "\n",
       "        [[-0.7825, -1.4319, -0.0774],\n",
       "         [-0.9028, -1.6391,  0.5435],\n",
       "         [ 0.6942,  0.5163,  1.5398],\n",
       "         [-0.3060,  1.1971,  2.3434]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d7f11",
   "metadata": {},
   "source": [
    "### WIN PREDICTOR NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "3b048bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "        [7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
       "        [8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9]])]"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny, nx = 10, 10\n",
    "x, y = np.arange(nx), np.arange(ny)\n",
    "np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "060fabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes in cmp which is 2 dimensional \n",
    "# [ [10, 8],\n",
    "#   [84, 3] ]\n",
    "# Where i, j is the one hot representation of the champions on ith row, jth col\n",
    "# trained_vec is a dictionary that convert each champions into a vector formate of size 2\n",
    "\n",
    "def pretrain_init(cmp, champ2vec):\n",
    "    \n",
    "    def vectoring_champ(x):\n",
    "        return champ2vec.get(x)\n",
    "    \n",
    "    return np.vectorize(vectoring_champ)(cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "6f379d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Win_Predictor_Net(nn.Module):\n",
    "    def __init__(self, criterion, \n",
    "                 cmp_size = 85, embedding_size = 4, hidden_size = 10):\n",
    "        super(Win_Predictor_Net, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cmp_size = cmp_size\n",
    "        self.criterion = criterion\n",
    "        # Embeddings to learn for champions \n",
    "        self.layer_cmp_emb = nn.Embedding(\n",
    "            num_embeddings=self.cmp_size+1,\n",
    "            embedding_dim=self.embedding_size,\n",
    "            padding_idx=85)#the onehot representation for background (check later)\n",
    "        \n",
    "        self.layer_w_0_s = nn.Linear(\n",
    "            in_features=self.embedding_size*28,\n",
    "            out_features=self.hidden_size,\n",
    "            bias=True)\n",
    "        \n",
    "        self.layer_w_0_o = nn.Linear(\n",
    "            in_features=self.embedding_size*28,\n",
    "            out_features=self.hidden_size,\n",
    "            bias=True)\n",
    "\n",
    "        self.layer_w_1 = nn.Linear(\n",
    "            in_features=2*self.hidden_size,\n",
    "            out_features=1,\n",
    "            bias=True)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, scmp, ocmp, pretrain = False):\n",
    "\n",
    "        # champion level embedings\n",
    "        if not pretrain:\n",
    "            E_self = self.layer_cmp_emb(scmp)\n",
    "            E_opp = self.layer_cmp_emb(ocmp)\n",
    "        else:\n",
    "            E_self = pretrain_init(scmp)\n",
    "            E_opp = pretrain_init(ocmp)\n",
    "            \n",
    "        # SELF SIDE\n",
    "        s = E_self.view(-1, self.embedding_size)# (28 x self.embedding_size)\n",
    "        s = torch.flatten(s) #(28 x self.embedding_size, 1)\n",
    "        s = torch.tanh(self.layer_w_0_s(s))# (28 x self.hidden_size)\n",
    "\n",
    "        # OPPONENT SIDE\n",
    "        o = E_opp.view(-1, self.embedding_size)\n",
    "        o = torch.flatten(o) #(28 x self.embedding_size, 1)\n",
    "        o = torch.tanh(self.layer_w_0_o(o))\n",
    "        \n",
    "        # concat SELF AND OPPONENT\n",
    "        concat = torch.cat((s, o), axis = 0) # (2 x 28 x self.embedding_size,1)\n",
    "\n",
    "        x = self.layer_w_1(concat)\n",
    "\n",
    "        x = torch.tanh(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "21e402b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, num_epochs=25):\n",
    "    \n",
    "    since = time.time()\n",
    "    acc_list = []\n",
    "    model.train() # In training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs_s, inputs_o, labels in dataloaders:\n",
    "            inputs_s = inputs_s.to(device)\n",
    "            inputs_o = inputs_o.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs_s, inputs_o)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "            \n",
    "            preds = torch.round(outputs)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs_s.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Epoch information\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "        acc_list.append(epoch_acc)\n",
    "\n",
    "        print('Training Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "03d2b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloaders):\n",
    "    \n",
    "    since = time.time()\n",
    "    model.eval() # In training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs_s, inputs_o, labels in dataloaders:\n",
    "        inputs_s = inputs_s.to(device)\n",
    "        inputs_o = inputs_o.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs_s, inputs_o)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "\n",
    "            preds = torch.round(outputs)\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs_s.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    overall_loss = running_loss / len(dataloaders.dataset)\n",
    "    overall_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "\n",
    "    print('Evaluation Loss: {:.4f} Acc: {:.4f}'.format(overall_loss, overall_acc))\n",
    "    \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return overall_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817cea2",
   "metadata": {},
   "source": [
    "## Make data inputable:\n",
    "- input data should be (n, 4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "041c763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with predicted labels:\n",
    "#   useful columns: \n",
    "#           youtuber --> (only Mortdog for now)\n",
    "#           video_name\n",
    "#           frame_name\n",
    "#           cropped_name --> for positional value\n",
    "#           predicted --> for converting to one-hot\n",
    "\n",
    "champion_label_df = pd.read_csv(os.path.join(os.getcwd(), 'data', 'Champion_Label_FINAL.csv'))\n",
    "\n",
    "\n",
    "with open(\"data/master_champ_list.pkl\", \"rb\") as input_file:\n",
    "        master_champ_list = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "24de0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on only Mortdog data\n",
    "champion_label_df = champion_label_df[champion_label_df.youtuber == 'Mortdog']\n",
    "\n",
    "# Figure out the youtuber, video_name, frame_name keys that are valid for the input\n",
    "champion_label_df_count = champion_label_df[champion_label_df.youtuber == 'Mortdog'].groupby(['youtuber', 'video_name', 'frame_name']).size().reset_index(name='img_count')\n",
    "champion_label_df_count = champion_label_df_count[champion_label_df_count.img_count == 56]\n",
    "\n",
    "champion_label_df_count['y'] = np.nan\n",
    "\n",
    "champion_label_df_count = champion_label_df_count.loc[:, ['youtuber', 'video_name', 'frame_name', 'y']]\n",
    "\n",
    "# # Change data so it fits the DNN\n",
    "# s, o = format_for_dnn(champion_label_df, champion_label_df_count)\n",
    "\n",
    "# y = champion_label_df_count['y']# NEED TO LABEL AT SOME POINT\n",
    "\n",
    "\n",
    "\n",
    "# # # Uncomment if you need to relabel the win/loss\n",
    "# # path_to_win_loss_label = os.path.join(os.getcwd(), 'data', 'win_loss_label.csv')\n",
    "# # champion_label_df_count.to_csv(path_to_win_loss_label, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e3647",
   "metadata": {},
   "source": [
    "### DELETE CODE CHUNK BELOW WHEN IT 100% WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "7987ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on only Mortdog data\n",
    "sample_df = champion_label_df[champion_label_df.youtuber == 'Mortdog'][0:56*100]\n",
    "\n",
    "# Figure out the youtuber, video_name, frame_name keys that are valid for the input\n",
    "sample_df_count = sample_df[sample_df.youtuber == 'Mortdog'].groupby(['youtuber', 'video_name', 'frame_name']).size().reset_index(name='img_count')\n",
    "sample_df_count = sample_df_count[sample_df_count.img_count == 56]\n",
    "\n",
    "sample_df_count = sample_df_count.loc[:, ['youtuber', 'video_name', 'frame_name']]\n",
    "\n",
    "s, o = format_for_dnn(sample_df, sample_df_count)\n",
    "\n",
    "y = np.round(np.random.random(len(s))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d569d7f",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "1b4a5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "s_train, s_test, o_train, o_test, y_train, y_test = before_customimagedataset(s, o, y)\n",
    "\n",
    "trainset = CustomImageDataset(s_train, o_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "testset = CustomImageDataset(s_test, o_test, y_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ba3a7",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "da2237b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_predictor = Win_Predictor_Net(nn.BCELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "34f0c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_SGD = torch.optim.SGD(win_predictor.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "a3ef8888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Training Loss: 0.3159 Acc: 1.0000\n",
      "Epoch 1/4\n",
      "----------\n",
      "Training Loss: 0.3157 Acc: 1.0000\n",
      "Epoch 2/4\n",
      "----------\n",
      "Training Loss: 0.3155 Acc: 1.0000\n",
      "Epoch 3/4\n",
      "----------\n",
      "Training Loss: 0.3154 Acc: 1.0000\n",
      "Epoch 4/4\n",
      "----------\n",
      "Training Loss: 0.3152 Acc: 1.0000\n",
      "Training complete in 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(1., dtype=torch.float64),\n",
       " tensor(1., dtype=torch.float64),\n",
       " tensor(1., dtype=torch.float64),\n",
       " tensor(1., dtype=torch.float64),\n",
       " tensor(1., dtype=torch.float64)]"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(win_predictor, trainloader, optimizer_SGD, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e3ef9",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "a130fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.9011 Acc: 0.4000\n",
      "Training complete in 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4000, dtype=torch.float64)"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(win_predictor, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3c712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e924f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "49e578b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtuber</th>\n",
       "      <th>video_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>img_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mortdog</td>\n",
       "      <td>100 HP Challenger - Nerfed but still so good  ...</td>\n",
       "      <td>frame11880.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortdog</td>\n",
       "      <td>100 HP Challenger - Nerfed but still so good  ...</td>\n",
       "      <td>frame13710.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mortdog</td>\n",
       "      <td>100 HP Challenger - Nerfed but still so good  ...</td>\n",
       "      <td>frame15480.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mortdog</td>\n",
       "      <td>100 HP Challenger - Nerfed but still so good  ...</td>\n",
       "      <td>frame17220.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mortdog</td>\n",
       "      <td>100 HP Challenger - Nerfed but still so good  ...</td>\n",
       "      <td>frame1800.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  youtuber                                         video_name      frame_name  \\\n",
       "0  Mortdog  100 HP Challenger - Nerfed but still so good  ...  frame11880.jpg   \n",
       "1  Mortdog  100 HP Challenger - Nerfed but still so good  ...  frame13710.jpg   \n",
       "2  Mortdog  100 HP Challenger - Nerfed but still so good  ...  frame15480.jpg   \n",
       "3  Mortdog  100 HP Challenger - Nerfed but still so good  ...  frame17220.jpg   \n",
       "4  Mortdog  100 HP Challenger - Nerfed but still so good  ...   frame1800.jpg   \n",
       "\n",
       "   img_count  \n",
       "0         56  \n",
       "1         56  \n",
       "2         56  \n",
       "3         56  \n",
       "4         56  "
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
