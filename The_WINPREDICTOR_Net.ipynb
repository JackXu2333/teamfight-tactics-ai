{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c51363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "import platform\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Importing essential libraries for basic image manipulations.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tF\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dda42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Enable/Disable GPU \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, test=False):\n",
    "        img_labels = pd.read_csv(annotations_file, header = 0)\n",
    "        if test:\n",
    "            self.img_labels = img_labels.iloc[round(0.9 * img_labels.shape[0]):] \n",
    "        else:\n",
    "            self.img_labels = img_labels.iloc[:round(0.9 * img_labels.shape[0])]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a941aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomVerticalFlip(p=0.5),\n",
    "     transforms.RandomHorizontalFlip(p=0.5)])\n",
    "\n",
    "trainset = CustomImageDataset(annotations_file = './data/annotation_file.csv', \n",
    "                              img_dir='./data/champion-classifier', transform=transform, test=False)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "testset = CustomImageDataset(annotations_file = './data/annotation_file.csv', \n",
    "                              img_dir='./data/champion-classifier', transform=None, test=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "856a1e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2953,  0.9859,  1.0614],\n",
       "         [-1.5247, -0.5135, -2.0656],\n",
       "         [-0.1733,  0.8146,  0.3970],\n",
       "         [-0.1272,  0.3887, -0.3461]],\n",
       "\n",
       "        [[-0.1733,  0.8146,  0.3970],\n",
       "         [-2.0688, -0.6792,  0.1559],\n",
       "         [-1.5247, -0.5135, -2.0656],\n",
       "         [ 0.1893, -0.3965,  0.3569]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d7f11",
   "metadata": {},
   "source": [
    "### WIN PREDICTOR NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b048bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "        [7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
       "        [8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "        [9, 9, 9, 9, 9, 9, 9, 9, 9, 9]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny, nx = 10, 10\n",
    "x, y = np.arange(nx), np.arange(ny)\n",
    "np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes in cmp which is 2 dimensional \n",
    "# [ [10, 8],\n",
    "#   [84, 3] ]\n",
    "# Where i, j is the one hot representation of the champions on ith row, jth col\n",
    "# trained_vec is a dictionary that convert each champions into a vector formate of size 2\n",
    "\n",
    "def pretrain_init(cmp, champ2vec):\n",
    "    \n",
    "    def vectoring_champ(x):\n",
    "        return champ2vec.get(x)\n",
    "    \n",
    "    return np.vectorize(vectoring_champ)(cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f379d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Win_Predictor_Net(nn.Module):\n",
    "    def __init__(self, criterion, \n",
    "                 cmp_size = 84, embedding_size = 4, hidden_size = 10):\n",
    "        super(Win_Predictor_Net, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Embeddings to learn for champions \n",
    "        self.layer_cmp_emb = nn.Embedding(\n",
    "            num_embeddings=self.cmp_size+1,\n",
    "            embedding_dim=self.embedding_size,\n",
    "            padding_idx=0)\n",
    "        \n",
    "        self.layer_w_0 = nn.Linear(\n",
    "            in_features=self.embedding_size,\n",
    "            out_features=self.hidden_size,\n",
    "            bias=True)\n",
    "        \n",
    "        self.layer_w_1 = nn.Linear(\n",
    "            in_features=self.embedding_size,\n",
    "            out_features=1,\n",
    "            bias=True)\n",
    "        \n",
    "        self.sigmoid = nn.sigmoid()\n",
    "        \n",
    "    def forward(self, scmp, ocmp, pretrain = False):\n",
    "\n",
    "        # champion level embedings\n",
    "        if not pretrain:\n",
    "            E_self = self.layer_cmp_emb(scmp)\n",
    "            E_opp = self.layer_cmp_emb(ocmp)\n",
    "        else:\n",
    "            E_self = pretrain_init(scmp)\n",
    "            E_opp = pretrain_init(ocmp)\n",
    "            \n",
    "        E_self_flatten = E_self.view(-1, self.embedding_size)\n",
    "        E_Tself_flatten = torch.tanh(self.layer_w_0(E_self_flatten))\n",
    "        \n",
    "        E_opp_flatten = E_opp.view(-1, self.embedding_size)\n",
    "        E_Topp_flatten = torch.tanh(self.layer_w_0(E_opp_flatten))\n",
    "        \n",
    "        # concat\n",
    "        E_concat = torch.cat((E_Tself_flatten, E_Topp_flatten), 1)\n",
    "        E_concat_flatten = E_concat.view(-1, self.hidden_size)\n",
    "        E_Tconcat_flatten = torch.tanh(self.layer_w_1(E_concat_flatten))\n",
    "\n",
    "        return self.sigmoid(E_Tconcat_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e402b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, num_epochs=25):\n",
    "    \n",
    "    since = time.time()\n",
    "    acc_list = []\n",
    "    model.train() # In training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Epoch information\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "        acc_list.append(epoch_acc)\n",
    "\n",
    "        print('Training Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloaders):\n",
    "    \n",
    "    since = time.time()\n",
    "    model.eval() # In training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    overall_loss = running_loss / len(dataloaders.dataset)\n",
    "    overall_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "\n",
    "    print('Evaluation Loss: {:.4f} Acc: {:.4f}'.format(overall_loss, overall_acc))\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return overall_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
